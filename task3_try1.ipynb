{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1afa0576-22a6-48e4-847b-7e8a6aae3e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1, Best Fitness: 0.3335\n",
      "Generation 2, Best Fitness: 0.3205\n",
      "Generation 3, Best Fitness: 0.3335\n",
      "Generation 4, Best Fitness: 0.3335\n",
      "Generation 5, Best Fitness: 0.3335\n",
      "Generation 6, Best Fitness: 0.3335\n",
      "Generation 7, Best Fitness: 0.3335\n",
      "Generation 8, Best Fitness: 0.3335\n",
      "Generation 9, Best Fitness: 0.3335\n",
      "Generation 10, Best Fitness: 0.3335\n",
      "Optimal Hyperparameters: Learning Rate = 0.09674685321847672, Hidden Sizes = 128, 256\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from scipy.special import softmax\n",
    "\n",
    "df_test = pd.read_csv('mnist_test.csv')\n",
    "\n",
    "y = df_test['label'].values\n",
    "X = df_test.drop('label', axis=1).values\n",
    "X = X / 255.0\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y = encoder.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "generations = 10\n",
    "population_size = 10\n",
    "mutation_rate = 0.1\n",
    "\n",
    "# Define Genetic Algorithm Functions\n",
    "def create_chromosome():\n",
    "    learning_rate = np.random.uniform(0.001, 0.1)\n",
    "    hidden_size_1 = np.random.choice([32, 64, 128, 256])\n",
    "    hidden_size_2 = np.random.choice([32, 64, 128, 256])\n",
    "    return [learning_rate, hidden_size_1, hidden_size_2]\n",
    "\n",
    "def fitness(chromosome, X, y):\n",
    "    learning_rate, hidden_size_1, hidden_size_2 = chromosome\n",
    "    return train_and_evaluate(X, y, learning_rate, hidden_size_1, hidden_size_2)\n",
    "\n",
    "def select(population, fitness_scores):\n",
    "    sorted_population = [x for _, x in sorted(zip(fitness_scores, population), reverse=True)]\n",
    "    return sorted_population[:population_size // 2]\n",
    "\n",
    "def crossover(parent1, parent2):\n",
    "    point = np.random.randint(1, len(parent1))\n",
    "    child1 = parent1[:point] + parent2[point:]\n",
    "    child2 = parent2[:point] + parent1[point:]\n",
    "    return child1, child2\n",
    "\n",
    "def mutate(chromosome, mutation_rate):\n",
    "    if np.random.rand() < mutation_rate:\n",
    "        index = np.random.randint(0, len(chromosome))\n",
    "        if index == 0:\n",
    "            chromosome[index] = np.random.uniform(0.001, 0.1)\n",
    "        else:\n",
    "            chromosome[index] = np.random.choice([32, 64, 128, 256])\n",
    "    return chromosome\n",
    "\n",
    "def decode_chromosome(chromosome):\n",
    "    return chromosome\n",
    "\n",
    "def train_and_evaluate(X, y, learning_rate, hidden_size_1, hidden_size_2):\n",
    "    # Initialize parameters\n",
    "    input_size = 28 * 28\n",
    "    output_size = 10\n",
    "\n",
    "    # Weights initialization\n",
    "    np.random.seed(42)\n",
    "    W1 = np.random.rand(input_size, hidden_size_1) * 0.01\n",
    "    b1 = np.zeros((1, hidden_size_1))\n",
    "    W2 = np.random.rand(hidden_size_1, hidden_size_2) * 0.01\n",
    "    b2 = np.zeros((1, hidden_size_2))\n",
    "    W3 = np.random.rand(hidden_size_2, output_size) * 0.01\n",
    "    b3 = np.zeros((1, output_size))\n",
    "\n",
    "    epochs = 10\n",
    "    batch_size = 32\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(0, X_train.shape[0], batch_size):\n",
    "            # Get mini-batch\n",
    "            X_batch = X_train[i:i + batch_size]\n",
    "            y_batch = y_train[i:i + batch_size]\n",
    "\n",
    "            # Forward propagation\n",
    "            Z1 = np.dot(X_batch, W1) + b1\n",
    "            A1 = sigmoid(Z1)\n",
    "            Z2 = np.dot(A1, W2) + b2\n",
    "            A2 = sigmoid(Z2)\n",
    "            Z3 = np.dot(A2, W3) + b3\n",
    "            A3 = sigmoid(Z3)\n",
    "\n",
    "            # Backpropagation\n",
    "            dZ3 = A3 - y_batch\n",
    "            dW3 = np.dot(A2.T, dZ3) / batch_size\n",
    "            db3 = np.sum(dZ3, axis=0, keepdims=True) / batch_size\n",
    "\n",
    "            dZ2 = np.dot(dZ3, W3.T) * sigmoid_derivative(A2)\n",
    "            dW2 = np.dot(A1.T, dZ2) / batch_size\n",
    "            db2 = np.sum(dZ2, axis=0, keepdims=True) / batch_size\n",
    "\n",
    "            dZ1 = np.dot(dZ2, W2.T) * sigmoid_derivative(A1)\n",
    "            dW1 = np.dot(X_batch.T, dZ1) / batch_size\n",
    "            db1 = np.sum(dZ1, axis=0, keepdims=True) / batch_size\n",
    "\n",
    "            # Update weights and biases\n",
    "            W1 -= learning_rate * dW1\n",
    "            b1 -= learning_rate * db1\n",
    "            W2 -= learning_rate * dW2\n",
    "            b2 -= learning_rate * db2\n",
    "            W3 -= learning_rate * dW3\n",
    "            b3 -= learning_rate * db3\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    Z1_val = np.dot(X_val, W1) + b1\n",
    "    A1_val = sigmoid(Z1_val)\n",
    "    Z2_val = np.dot(A1_val, W2) + b2\n",
    "    A2_val = sigmoid(Z2_val)\n",
    "    Z3_val = np.dot(A2_val, W3) + b3\n",
    "    A3_val = sigmoid(Z3_val)\n",
    "    A3_val = softmax(A3_val, axis=1)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    val_predictions = np.argmax(A3_val, axis=1)\n",
    "    val_true = np.argmax(y_val, axis=1)\n",
    "    val_accuracy = accuracy_score(val_true, val_predictions)\n",
    "\n",
    "    return val_accuracy\n",
    "\n",
    "# Genetic Algorithm Execution\n",
    "population = [create_chromosome() for _ in range(population_size)]\n",
    "for generation in range(generations):\n",
    "    fitness_scores = [fitness(chromosome, X_train, y_train) for chromosome in population]\n",
    "    print(f\"Generation {generation+1}, Best Fitness: {max(fitness_scores):.4f}\")\n",
    "    \n",
    "    selected = select(population, fitness_scores)\n",
    "    next_generation = []\n",
    "    \n",
    "    while len(next_generation) < population_size:\n",
    "        parent1, parent2 = random.sample(selected, 2)\n",
    "        child1, child2 = crossover(parent1, parent2)\n",
    "        next_generation.append(mutate(child1, mutation_rate))\n",
    "        next_generation.append(mutate(child2, mutation_rate))\n",
    "    \n",
    "    population = next_generation\n",
    "\n",
    "best_chromosome = max(population, key=lambda chromo: fitness(chromo, X_train, y_train))\n",
    "best_learning_rate, best_hidden_size_1, best_hidden_size_2 = decode_chromosome(best_chromosome)\n",
    "print(f\"Optimal Hyperparameters: Learning Rate = {best_learning_rate}, Hidden Sizes = {best_hidden_size_1}, {best_hidden_size_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d865eec-4d98-40e0-a9ee-984d8a021269",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
